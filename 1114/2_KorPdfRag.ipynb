{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17d45ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from korPdfRag import PdfRAGSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae883a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Korean embeddings model: intfloat/multilingual-e5-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\C117\\miniconda3\\envs\\llmEnv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\C117\\.cache\\huggingface\\hub\\models--intfloat--multilingual-e5-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index: pdf-manual-index\n",
      "Index created successfully!\n"
     ]
    }
   ],
   "source": [
    "# RAG 사용 객체 생성\n",
    "rag_system = PdfRAGSystem()\n",
    "\n",
    "# 인덱스 생성하기\n",
    "rag_system.create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c86c7349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDF: cuckoo_레시피.pdf\n",
      "Loaded 56 pages, type: <class 'list'>\n",
      "After filtering image-only pages: 56 pages\n",
      "Split into 65 chunks\n",
      "page_content='영\n",
      "양\n",
      "가\n",
      "득\n",
      "한\n",
      "그\n",
      "릇\n",
      "밥\n",
      "난이도별\n",
      "한그릇 레시피' metadata={'source': 'cuckoo_레시피.pdf', 'file_path': 'cuckoo_레시피.pdf', 'page': 0, 'total_pages': 56, 'Author': 'imac1', 'CreationDate': \"D:20231115110537+09'00'\", 'Creator': 'QuarkXPress(R) 14.12', 'ModDate': \"D:20231115110712+09'00'\", 'Producer': 'QuarkXPress(R) 14.12', 'Title': '???? 1', 'XPressPrivate': '%%DocumentProcessColors: Cyan Magenta Yellow Black\\n%%EndComments'}\n"
     ]
    }
   ],
   "source": [
    "# PDF 문서 로드\n",
    "pdf_path='cuckoo_레시피.pdf'\n",
    "\n",
    "# 청킹된 결과를 만듭니다. 리턴타입이 Document 객체의 리스트 \n",
    "chunks = rag_system.load_and_split_pdf(\n",
    "    pdf_path=pdf_path,\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26397652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunks[0].id : None\n",
      "chunks[0].metadata : {'source': 'cuckoo_레시피.pdf', 'file_path': 'cuckoo_레시피.pdf', 'page': 0, 'total_pages': 56, 'Author': 'imac1', 'CreationDate': \"D:20231115110537+09'00'\", 'Creator': 'QuarkXPress(R) 14.12', 'ModDate': \"D:20231115110712+09'00'\", 'Producer': 'QuarkXPress(R) 14.12', 'Title': '???? 1', 'XPressPrivate': '%%DocumentProcessColors: Cyan Magenta Yellow Black\\n%%EndComments', 'text': '영\\n양\\n가\\n득\\n한\\n그\\n릇\\n밥\\n난이도별\\n한그릇 레시피'}\n",
      "chunks[0].page_content : 영\n",
      "양\n",
      "가\n",
      "득\n",
      "한\n",
      "그\n",
      "릇\n",
      "밥\n",
      "난이도별\n",
      "한그릇 레시피\n",
      "chunks[0].type : Document\n"
     ]
    }
   ],
   "source": [
    "print('chunks[0].id :',chunks[0].id)\n",
    "print('chunks[0].metadata :',chunks[0].metadata)\n",
    "print('chunks[0].page_content :',chunks[0].page_content)\n",
    "print('chunks[0].type :',chunks[0].type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3bbd5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c885ff0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vector store and embedding documents with Korean model...\n",
      "Vector store created successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x23189843c50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 업서트\n",
    "rag_system.create_vectorstore(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abb24847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "035259b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing vector store...\n",
      "Vector store loaded!\n"
     ]
    }
   ],
   "source": [
    "# 지정된 인덱스의 벡터값 가져오기\n",
    "vectorstore = rag_system.load_vectorstore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8a0a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩된 검색(retriever) 객체 생성 : 파이프라인으로 사용\n",
    "# docs = vector_store.similarity_search(query=question[0], k=5, namespace=\"wiki-ns1\") 는 query 로 유사도 검색\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5}          # 검색결과에서 유사도 순서로 5개 가져오기\n",
    ")\n",
    "        \n",
    "# 한글 프롬프트 : docstring 에서는 f'' 없이 입력변수 {} 지정\n",
    "template = \"\"\"당신은 제품 매뉴얼 기반 질의응답 전문가입니다.\n",
    "주어진  바탕으로 사용자의 질문에 정확하고 상세하게 답변해주세요.\n",
    "\n",
    "답변 시 주의사항:\n",
    "- 컨텍스트에 정보가 있으면 그것을 기반으로 답변하세요.\n",
    "- 컨텍스트에 없는 내용은 \"제공된 매뉴얼에서 해당 정보를 찾을 수 없습니다\"라고 답변하세요.\n",
    "- 한글로 명확하고 이해하기 쉽게 설명하세요.\n",
    "- 필요하면 단계별 설명을 제공하세요.\n",
    "\n",
    "컨텍스트:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f205924f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['PineconeVectorStore', 'KoreanEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x0000023189CB5700>, search_kwargs={'k': 5})\n",
       "           | RunnableLambda(format_docs),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='당신은 제품 매뉴얼 기반 질의응답 전문가입니다.\\n주어진  바탕으로 사용자의 질문에 정확하고 상세하게 답변해주세요.\\n\\n답변 시 주의사항:\\n- 컨텍스트에 정보가 있으면 그것을 기반으로 답변하세요.\\n- 컨텍스트에 없는 내용은 \"제공된 매뉴얼에서 해당 정보를 찾을 수 없습니다\"라고 답변하세요.\\n- 한글로 명확하고 이해하기 쉽게 설명하세요.\\n- 필요하면 단계별 설명을 제공하세요.\\n\\n컨텍스트:\\n{context}\\n\\n질문: {question}\\n\\n답변:'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000230461233B0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000230464ACEC0>, root_client=<openai.OpenAI object at 0x000002318B347BF0>, root_async_client=<openai.AsyncOpenAI object at 0x000002307A9FAAB0>, model_name='gpt-4.1-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True)\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4.1-mini',temperature=0)\n",
    "\n",
    "# RAG 체인 구성\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "140d5afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: tomato bacon 요리방법\n",
      "------------------------------------------------------------\n",
      "답변: tomato bacon 요리방법은 다음과 같습니다.\n",
      "\n",
      "1. 베이컨 6줄을 1cm 두께로 썰고, 방울토마토 10개는 깨끗이 씻어 준비합니다.\n",
      "2. 깨끗이 씻은 쌀 2컵(300g)을 내솥에 넣고, 무압백미 물눈금 2까지 물을 부어줍니다.\n",
      "3. 그 위에 썰어둔 베이컨을 올립니다.\n",
      "4. 뚜껑을 닫고 핸들 손잡이를 무압모드로 돌립니다.\n",
      "5. 좌/우 버튼으로 [영양밥-1단계] 메뉴를 선택한 후 시작 버튼을 눌러 취사를 시작합니다.\n",
      "6. 취사 시작 후 20분이 지나면 오픈쿠킹 버튼을 눌러 뚜껑을 열고, 방울토마토를 넣은 뒤 뚜껑을 닫습니다. (뚜껑을 닫으면 취사가 계속 진행됩니다.)\n",
      "7. 취사가 완료되면 올리브유 1큰술을 두르고, 파슬리 약간을 올려 마무리합니다.\n",
      "\n",
      "주의사항: 방울토마토는 반드시 오픈쿠킹 기능을 활용하여 취사 중간에 넣어야 하며, 지정된 용량을 초과하지 않도록 주의하세요. 끓어 넘침이 발생할 수 있습니다.\n",
      "\n",
      "\n",
      "질문: tomato bacon 재료\n",
      "------------------------------------------------------------\n",
      "답변: tomato bacon 요리에 필요한 재료는 다음과 같습니다.\n",
      "\n",
      "- 쌀 2컵 (300g)  \n",
      "- 베이컨 6줄  \n",
      "- 방울토마토 10개  \n",
      "- 올리브유 1큰술  \n",
      "- 파슬리 약간  \n",
      "\n",
      "이 재료들을 사용하여 조리하시면 됩니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# questions = [\n",
    "# \"스팸김치날치알 요리방법\",\n",
    "# \"스팸김치날치알 재료\",\n",
    "# ]\n",
    "\n",
    "questions = [\n",
    "\"tomato bacon 요리방법\",\n",
    "\"tomato bacon 재료\",\n",
    "]\n",
    "for question in questions:\n",
    "    print(f\"\\n질문: {question}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # 답변만 받기\n",
    "    answer = rag_chain.invoke(question)\n",
    "    print(f\"답변: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a582049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KoreanEmbeddings 의 속성 : embeddingsa\n",
    "# PdfRAGSystem 의 속성 \n",
    "# index_name 문자열, pc(파인콘),embeddings,llm,vectorstore 객체\n",
    "'''\n",
    "PDF 메뉴얼 기반 RAG 시스템 - Pinecone + LangChain 1.x\n",
    "\n",
    "한글 특화 임베딩 모델 + 이미지 무시\n",
    "- 백터DB 에 저장할 문서(텍스트)는 PDF 에서 가져옵니다.\n",
    "- 파인콘에 백터DB 저장\n",
    "    - 임베딩 모델, 인덱스 이름 결정\n",
    "    - PineconeVectorStore : vectorstore 객체로 저장\n",
    "\n",
    "- 파인콘에 저장된 index 에서 검색(유사도 검색)\n",
    "    - PineconeVectorStore : vectorstore 객체에서 검색\n",
    "    - 조회 결과로 만들어진 텍스트는 llm 에게 전달하여 최종 응답 메세지 완성\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bd15583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Korean embeddings model: intfloat/multilingual-e5-large\n",
      "Index 'pdf-manual-index' already exists.\n",
      "Loading existing vector store...\n",
      "Vector store loaded!\n",
      "\n",
      "============================================================\n",
      "PDF 매뉴얼 RAG 시스템 (한글 특화)\n",
      "============================================================\n",
      "\n",
      "질문: 구우치즈밥 요리방법\n",
      "------------------------------------------------------------\n",
      "답변: 구우치즈밥 요리방법은 다음과 같습니다.\n",
      "\n",
      "1. 깨끗이 씻은 쌀 2컵(300g)을 내솥에 넣고 무압백미 물눈금 2까지 물을 부어줍니다.  \n",
      "2. 뚜껑을 닫고 핸들 손잡이를 무압모드로 돌려줍니다.  \n",
      "3. 좌/우 버튼으로 [영양밥-1단계] 메뉴를 선택한 후 시작 버튼을 눌러 취사를 시작합니다.  \n",
      "4. 취사 시작 20분 뒤 오픈쿠킹 버튼을 눌러 뚜껑을 열고 레토르트 카레 400g을 부어 잘 섞은 후, 밥 한가운데를 오목하게 만들어 계란 1개를 깨서 넣습니다.  \n",
      "5. 그 위에 슬라이스 치즈 1장과 모짜렐라 치즈 50g을 올리고 뚜껑을 닫으면 취사가 계속 진행됩니다.  \n",
      "6. 취사가 완료되면 뚜껑을 열어 파슬리를 약간 뿌려 마무리합니다.\n",
      "\n",
      "**주의사항:**  \n",
      "- 카레, 치즈, 계란은 오픈쿠킹 기능을 활용하여 취사 중간에 넣어야 하며, 반드시 레시피에 명시된 투입 시점을 지켜주세요.  \n",
      "- 지정된 용량을 초과하지 마십시오. 끓어 넘침이 발생할 수 있습니다.  \n",
      "\n",
      "이상으로 구우치즈밥의 상세한 요리방법입니다.\n",
      "\n",
      "\n",
      "질문: 구우치즈밥 재료\n",
      "------------------------------------------------------------\n",
      "답변: 구우치즈밥 재료는 다음과 같습니다.\n",
      "\n",
      "- 쌀 2컵 (300g)  \n",
      "- 레토르트 카레 400g  \n",
      "- 슬라이스 치즈 1장  \n",
      "- 모짜렐라 치즈 50g  \n",
      "- 계란 1개  \n",
      "- 파슬리 약간  \n",
      "\n",
      "이 재료들을 사용하여 구우치즈밥을 만드실 수 있습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  여기까지는 테스트.\n",
    "# 실제 실행은 main 함수로\n",
    "import korPdfRag\n",
    "\n",
    "questions = [\n",
    "\"구우치즈밥 요리방법\",\n",
    "\"구우치즈밥 재료\",\n",
    "]\n",
    "korPdfRag.main(False, None,'pdf-manual-index',questions)\n",
    "# False 는 다시 upsert 하지 않도록"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
