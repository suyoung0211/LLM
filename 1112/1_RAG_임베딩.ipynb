{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b84a5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3a846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=os.getenv('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b21d4bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone,ServerlessSpec\n",
    "pine = Pinecone(api_key=PINECONE_API_KEY)\n",
    "# pine = Pinecone(api_key=os.getenv('PINECONE_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90284964",
   "metadata": {},
   "source": [
    "- 인덱스 생성(서버리스)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b58b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name='wiki'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9488f54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"name\": \"wiki\",\n",
       "    \"metric\": \"cosine\",\n",
       "    \"host\": \"wiki-3h3vqd5.svc.aped-4627-b74a.pinecone.io\",\n",
       "    \"spec\": {\n",
       "        \"serverless\": {\n",
       "            \"cloud\": \"aws\",\n",
       "            \"region\": \"us-east-1\"\n",
       "        }\n",
       "    },\n",
       "    \"status\": {\n",
       "        \"ready\": true,\n",
       "        \"state\": \"Ready\"\n",
       "    },\n",
       "    \"vector_type\": \"dense\",\n",
       "    \"dimension\": 1536,\n",
       "    \"deletion_protection\": \"disabled\",\n",
       "    \"tags\": null\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pine.create_index(\n",
    "    name=index_name,\n",
    "    dimension=1536,\n",
    "    metric='cosine',\n",
    "    spec=ServerlessSpec(cloud='aws',region='us-east-1')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f40376",
   "metadata": {},
   "source": [
    "- 임베딩 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "13146e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'cosine',\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용할 인덱스 가져오기\n",
    "index = pine.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf20d2e3",
   "metadata": {},
   "source": [
    "- 임베딩 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eaf365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델의 차원(dimension) 과 생성한 인덱스의 차원(dimension) 이 같아야 합니다.\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403a6853",
   "metadata": {},
   "source": [
    "- 벡터DB 에 저장할 데이터셋 가져오기\n",
    "    - 영어로 된 20231101 버전의 위키백과 600만개의 row 중 100개만 가져오기(❌ 사용 안함)\n",
    "    - https://huggingface.co/datasets/wikimedia/wikipedia/tree/main/20231101.en 에서 다운받은 데이터 사용(✅ 사용)\n",
    "    - 데이터의 크기가 크면 임베딩 시간이 오래 걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b62e79d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\C117\\miniconda3\\envs\\llmEnv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# pip install datasets\n",
    "# dataset = load_dataset('wikimedia/wikipedia','20231101.en',split='train[:100]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdd8115",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('parquet',data_files=['train-03.parquet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aee519e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.dataset_dict.DatasetDict'>\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'url', 'title', 'text'],\n",
      "        num_rows: 156289\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset))    # dict\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8fbed346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data): 4\n",
      "len(data['text']): 1000\n"
     ]
    }
   ],
   "source": [
    "data = dataset['train'][:1000]\n",
    "print('len(data):',len(data))                       # dict 형태라 갯수 4개(칼럼이 4개)\n",
    "print('len(data[\\'text\\']):',len(data['text']))     # key 각각의 data 갯수 1000개씩\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b7b6fefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'url', 'title', 'text'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7b6f5e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Niklas Hogner (born 29 September 1984 in Linköping, Sweden) is a Swedish figure skater. Until 2003, he competed as a singles skater, winning four Swedish junior national titles and competing at the World Junior Figure Skating Championships.\\n\\nHe switched to pair skating, teaming up with partner Angelika Pylkina in 2003. They were the first Swedish pairs team to compete internationally since 1962. They twice placed 5th at the World Junior Championships and won three bronze medals on the Junior Grand Prix circuit. They won the bronze medal at the 2006 Nebelhorn Trophy and won the Nordic Championships. They ended their partnership in 2007.\\n\\nPrograms \\n(with Pylkina)\\n\\nResults\\n\\nPair skating with Pylkina\\n\\nSingle skating\\n\\nReferences\\n\\nExternal links\\n\\n \\n \\n\\n1984 births\\nLiving people\\nSportspeople from Linköping\\nSwedish male single skaters\\nSwedish male pair skaters'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b084038",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "50",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# 오류남\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 50"
     ]
    }
   ],
   "source": [
    "data[50] # 오류남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1cf591a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data) : 100\n"
     ]
    }
   ],
   "source": [
    "data = dataset['train'].select(range(100))\n",
    "print('len(data) :',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a470e666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '8125821',\n",
       " 'url': 'https://en.wikipedia.org/wiki/List%20of%20programs%20broadcast%20by%20G4',\n",
       " 'title': 'List of programs broadcast by G4',\n",
       " 'text': \"This is a list of television programs formerly broadcast by the U.S. cable television channel G4.\\n\\nSecond iteration\\n\\nFinal programming\\n\\nOriginal\\n\\n Xplay (2004–2013; 2013–2014 (reruns); 2021–2022)\\n Attack of the Show! (2005–2013; 2021–2022)\\n Invitation to Party (2021–2022)\\n Ninja Warrior (Sasuke and Kunoichi) (2006–2012, 2021–2022 (reruns))\\n Unbeatable Banzuke (2008–2010; 2021–2022 (reruns))\\n G4 Vault (2021–2022)\\n G4's Crash Course (2021–2022)\\n G4 Specials (2002–2012; 2021–2022)\\n Scott the Woz (2021–2022)\\n Name Your Price (2022)\\n G4 Gameday LCS (2022)\\n Arena (2002–2005; 2022)\\n Hey, Donna! (2022)\\n God of Work (2022)\\n\\nAcquired\\n Starcade (2002–2004; 2021-2022)\\n Takeshi's Castle Thailand (2021-2022)\\n Viva La Dirt League (2022)\\n Smosh (2022)\\n\\nFormer programming\\n\\nOriginal\\n Boosted (February–July 2021 (YouTube-exclusive); 2021–2022 (TV))\\n\\nOriginal iteration\\n\\nFormer programming\\n\\nOriginal \\n\\n Blister (2002–2004)\\n Cheat! (2002–2009)\\n Cinematech (2002–2007)\\n Filter (2002–2006)\\n G4tv.com (2002–2005)\\n Game Makers (2002–2005)\\n Game On (2002–2004)\\n Icons (2002–2007)\\n Judgment Day (2002–2006)\\n Players (2002–2004)\\n Portal (2002–2004)\\n Pulse (2002–2004)\\n Sweat (2003–2005)\\n The Electric Playground (2003–2006)\\n Eye Drops (2004)\\n Fresh Gear (2004)\\n Future Fighting Machines (2004–2005)\\n G4 Sports (2004–2005)\\n Invent This! (2004; reruns)\\n Nerd Nation (2004; reruns)\\n The Screen Savers (2004–2005)\\n Unscrewed with Martin Sargent (2004–2005)\\n Cinematech: Nocturnal Emissions (2005–2007)\\n Formula D (2005–2006)\\n G4's Late Night Peepshow (2005–2006)\\n G4's Training Camp (2005–2006)\\n Street Fury (2005–2006)\\n Video Game Vixens (2005)\\n Wired For Sex (2006–2008)\\n The Block (2007–2008)\\n Boost Mobile MLG Pro Circuit (2007)\\n Code Monkeys (2007–2008)\\n Free Stuff (2007)\\n Whacked Out Videos (2007–2009)\\n Human Wrecking Balls (2008–2010; 2014; reruns)\\n Hurl! (2008)\\n Spaceballs: The Animated Series (2008)\\n 2 Months 2 Million (2009; 2014; reruns)\\n American Ninja Warrior (2009–2013)\\n Campus PD (2009–2012; 2012–2014; reruns)\\n G4 Underground (2009)\\n The International Sexy Ladies Show (2009–2010)\\n Web Soup (2009–2011; 2014; reruns)\\n It's Effin' Science (2010; 2014; reruns)\\n Rated 'A' for Adult (2010–2011)\\n That's Tough (2010; 2014; reruns)\\n Bomb Patrol Afghanistan (2011–2013)\\n G4's Proving Ground (2011; 2014; reruns)\\n Jump City: Seattle (2011)\\n Top 100 Video Games of All Time (2012 TV special)\\n\\nAcquired \\n\\n 10 Play (2003–2004)\\n Game Gods (2003–2004)\\n Gamer.tv (2003–2004)\\n Game Sauce (2003–2004)\\n Hi-Score (2003–2004)\\n Body Hits (2004)\\n Robot Wars (2004–2006)\\n Thunderbirds (2004)\\n Call for Help (2005–2006)\\n The Man Show (2005–2007)\\n Brainiac: Science Abuse (2005–2008)\\n Fastlane (2005)\\n Happy Tree Friends (2005–2007)\\n Star Trek (2005–2006)\\n Star Trek: The Next Generation (2005–2006)\\n Arrested Development (2006–2009)\\n Banzai (2006–2007)\\n Cheaters (2006–2012)\\n Cops (2006–2014)\\n The Jamie Kennedy Experiment (2006–2008)\\n Super Big Product Fun Show (2007–2008)\\n Totally Outrageous Behavior (2007–2010)\\n Freaky (2008)\\n Heroes (2008–2010, 2012–2014)\\n The Peter Serafinowicz Show (2008–2009)\\n Trigger Happy TV (2008–2009)\\n Lost (2009–2010, 2012–2014)\\n The Chaser's War on Everything (2009–2010)\\n Viper's Creed (2009)\\n Blade (2011)\\n Iron Man (2011–2014)\\n Quantum Leap (2011–2012, 2013)\\n Wolverine (2011–2014)\\n X-Men (2011–2014)\\n Knight Rider (2012–2013)\\n Street Patrol (2012–2013)\\n Tremors: The Series (2012)\\n Airwolf (2013)\\n Voyagers! (2013)\\n\\nProgramming blocks \\n Expansion Pack (2002–2003)\\n G4 Global Gamer (2003–2004)\\n Real Time (2003–2005)\\n Anime Unleashed (2004–2006) (originated on TechTV and later moved to G4techTV when the channel merged with G4)\\n G-Spot (2004–2005)\\n The Whip Set (2005)\\n Barbed Wire Biscuit (2005–2006)\\n Action Blast! (2006–2007)\\n Duty Free TV (2006–2010)\\n G4 Rewind (2008–2009)\\n Junk Food TV (2009–2010)\\n\\nMovie presentations \\n Movies That Don't Suck (2008–2012; films were unbranded after 2012)\\n\\nAnnual event specials \\n Comic-Con International\\n Consumer Electronics Show\\n E3\\n\\nX-Play All Access \\n BlizzCon\\n D.I.C.E. Summit\\n Game Developers Conference\\n Gamescom\\n Interactive Achievement Awards\\n Penny Arcade Expo\\n QuakeCon\\n Tokyo Game Show\\n\\nWeb shows\\n\\nFormer \\n Feedback\\n Fighting Words\\n First 15\\n Fresh Ink Online\\n Sessler's Soapbox\\n Talkabouts\\n Happy Tree Friends\\n The MMO Report (2007–2012)\\n The Electric Playground\\n\\nCurrent \\n Facecheck Podcast (G4 Esports)\\n Fresh Ink\\n Full Screen Attack\\n Saints & Sinners Podcast (G4 Esports)\\n Sessler's Soapbox\\n The Feedback w/ Fiona Nova\\n Xplay Kickback\\n\\nG-Spot shorts \\nMost of these interstitial programs are AOTS and X-Play segments that aired outside the programs during some commercial breaks prior to May 20, 2012.\\n Epic Fail - A segment showing viral videos of spectacular fails.\\n The Feed - An AOTS host would give top stories in the gaming, tech, TV, and movie industry.\\n Filter - In this condensed version, a host would give Top 3 lists, such as the Top 3 Video Gaming Vixens.\\n G4 Urban Dictionary\\n Game Break - News and views on the latest in the world of video games, as presented by the experts that rate them.\\n Indie Games - Hosted by Kevin Pereira, this segment shows the latest independently-made video games.\\n Morgan Minute - Hosted by Morgan Webb, this segment shows the latest games designed specifically for women.\\n Tech Alert - This segment shows the latest and cool gadgets. These are rated on a scale of 1-5.\\n We've Got Questions, You've Got Answers - The staff of G4 posts a question, and viewers take to their webcams for their responses.\\n\\nReferences\\n\\n \\nG4\"}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[50]    # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902d9359",
   "metadata": {},
   "source": [
    "- 청크\n",
    "    - splitter 객체를 생성해서 문자열 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1186e939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "534d4244",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,             # 텍스트 분할 크기\n",
    "    chunk_overlap=20,           # 분할할 텍스트의 중첩 크기\n",
    "    length_function=len,\n",
    "    separators=['\\n',' ']       # 분할할때 사용할 텍스트(단어) 구분자\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052c9a38",
   "metadata": {},
   "source": [
    "- 청킹 후 임베딩 -> 업서트 : batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee11b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "import time\n",
    "\n",
    "# 한 번에 처리(업서트)할 데이터의 개수를 지정합니다.\n",
    "# batch_size 만큼 청크(chunk)를 모은 후, 한 번에 임베딩과 업서트를 수행합니다.\n",
    "batch_size = 30\n",
    "\n",
    "# 텍스트 청크(chunk)들을 임시로 저장할 리스트입니다.\n",
    "# 일정 개수(batch_size)만큼 모이면 임베딩 처리 후 벡터DB에 업서트됩니다.\n",
    "texts = []\n",
    "\n",
    "# 각 텍스트 청크에 대응하는 메타데이터(문서 ID, 제목, URL 등)를 저장할 리스트입니다.\n",
    "# texts 리스트와 인덱스가 동일하게 매칭됩니다.\n",
    "metas = []\n",
    "\n",
    "# 지금까지 처리한 청크(chunk)의 총 개수를 세는 카운터입니다.\n",
    "# batch_size 개수에 도달하면 임베딩 및 업서트 작업을 수행하고 다시 0부터 세기 시작합니다.\n",
    "count = 0\n",
    "\n",
    "# 데이터셋의 각 샘플에 대해 반복합니다.  tqdm 은 data를 감싸기만 하여 진행 상황을 표시하도록 합니다.\n",
    "for i, sample in enumerate(data):\n",
    "    full_text = sample['text']          # Wikipedia 문서 텍스트 -> 청킹 후 임베딩\n",
    "    \n",
    "    # metadata key 구성은 임의로 합니다. 청킹된 데이터의 소속을 구별\n",
    "    metadata = {\n",
    "        'wiki_id': sample[\"id\"],        # Wikipedia 문서 ID\n",
    "        'url':sample['url'],            # Wikipedia 문서 URL\n",
    "        'title': sample[\"title\"]        # Wikipedia 문서 제목\n",
    "    }\n",
    "\n",
    "\n",
    "    chunks = splitter.split_text(full_text)  # 텍스트를 청크로 분할합니다.\n",
    "    print(len(chunks))\n",
    "\n",
    "    # 각 청크에 대해 반복합니다.\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # 실제로 벡터BD 에 업서트할 record\n",
    "        record = {\n",
    "            'chunk_id': i,  # 청크 ID\n",
    "            'head_chunk': chunk[:200],  # 전체 텍스트\n",
    "            **metadata,  # 메타데이터 언패킹\n",
    "        }\n",
    "\n",
    "        texts.append(chunk)     # 청크를 텍스트 목록에 추가합니다.\n",
    "        metas.append(record)    # 메타데이터를 메타데이터 목록에 추가합니다.\n",
    "\n",
    "        count += 1  # 처리된 청크 수를 증가시킵니다.\n",
    "\n",
    "        # batch_size만큼의 청크를 처리 : 임베딩 -> 업서트\n",
    "        if count % batch_size == 0:\n",
    "            # Pinecone 인덱스에 청크를 추가합니다.\n",
    "            ids = [str(uuid4()) for _ in range(len(texts))]\n",
    "            embeddings = embedding.embed_documents(texts)\n",
    "            index.upsert(\n",
    "                vectors=zip(ids, embeddings, metas),\n",
    "                namespace=\"wiki-ns1\")\n",
    "            \n",
    "            # 청크 목록과 메타데이터 목록을 비웁니다.\n",
    "            texts = []\n",
    "            metas = []\n",
    "\n",
    "            # 1초 대기합니다.\n",
    "            time.sleep(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
