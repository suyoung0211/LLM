{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309c4844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b5da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c31a570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¬AI: ì£„ì†¡í•˜ì§€ë§Œ í˜„ì¬ ì €ëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ì¸í„°ë„·ì— ì ‘ì†í•´ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ í•œêµ­ í‘œì¤€ì‹œ(KST)ëŠ” UTC+9 ì‹œê°„ëŒ€ì— ìˆìœ¼ë¯€ë¡œ, ì‚¬ìš©ìì˜ í˜„ì¬ ì‹œê°„ì— ë§ì¶° ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í˜„ì¬ ì»´í“¨í„°ë‚˜ íœ´ëŒ€í°ì—ì„œ ì‹œê°„ì„ í™•ì¸í•˜ì‹œëŠ” ê²ƒì´ ê°€ì¥ ì •í™•í•©ë‹ˆë‹¤. ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "question = input(\"ì‚¬ìš©ì ìš”ì²­ ë©”ì‹œì§€\")\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4.1-mini',\n",
    "    messages=[\n",
    "        # AI ê°€ í• ì¼\n",
    "        {\"role\":\"system\",\"content\":\"You are a helpful assistant.using locale language.\"},\n",
    "        # ì‚¬ìš©ì ìš”ì²­\n",
    "        {\"role\":\"user\",\"content\":question}\n",
    "    ],\n",
    ")\n",
    "print(f'ğŸ’¬AI: {response.choices[0].message.content}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d2b4071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log : 12:02:48\n",
      "log : 2025:11:06\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤ì‹œê°„ ë°ì´í„°ëŠ” LLM ì˜ í•™ìŠµ ë‚´ìš©ì´ ì•„ë‹™ë‹ˆë‹¤.\n",
    "# ã„´ í•¨ìˆ˜ í˜¸ì¶œ ë˜ëŠ” tools ì‚¬ìš©í•´ì„œ ë‹µë³€ì„ í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "# ì‹œê°„ êµ¬í•˜ê¸° í•¨ìˆ˜\n",
    "from datetime import datetime\n",
    "\n",
    "def get_current_time():\n",
    "    now = datetime.now().strftime('%H:%M:%S')\n",
    "    print(f'log : {now}')\n",
    "    return now\n",
    "\n",
    "get_current_time()\n",
    "\n",
    "# ë‚ ì§œ êµ¬í•˜ê¸° í•¨ìˆ˜ : ì˜ˆì •\n",
    "def get_current_date():\n",
    "    now = datetime.now().strftime('%Y:%m:%d')\n",
    "    print(f'log : {now}')\n",
    "    return now\n",
    "\n",
    "get_current_date()\n",
    "\n",
    "\n",
    "# gpt ê°€ ì‚¬ìš©í•  í•¨ìˆ˜ ëª©ë¡ì„ ì •ì˜\n",
    "myfunctions = [\n",
    "    {\n",
    "        'name' : 'get_current_time',\n",
    "        'description':'í˜„ì¬ ì‹œê°„ ì¶œë ¥. í¬ë§· HH:MM:SS',\n",
    "    },\n",
    "    {\n",
    "        'name' : 'get_current_date',\n",
    "        'description':'í˜„ì¬ ì‹œê°„ ì¶œë ¥. í¬ë§· YYYY:MM:DD'\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8008c339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log response : {\n",
      "  \"id\": \"chatcmpl-CYkffrFAsPqoeZ0vruIFFSPpHnzsO\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"function_call\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": null,\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": [],\n",
      "        \"audio\": null,\n",
      "        \"function_call\": {\n",
      "          \"arguments\": \"{}\",\n",
      "          \"name\": \"get_current_time\"\n",
      "        },\n",
      "        \"tool_calls\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1762398591,\n",
      "  \"model\": \"gpt-4.1-mini-2025-04-14\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": \"fp_4c2851f862\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 11,\n",
      "    \"prompt_tokens\": 81,\n",
      "    \"total_tokens\": 92,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = 'í˜„ì¬ ì‹œê°„ ì•Œë ¤ì¤˜'\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4.1-mini',\n",
    "    messages=[\n",
    "        {\"role\":\"system\",\"content\":\"You are a helpful assistant.using locale language.\"},\n",
    "        {\"role\":\"user\",\"content\":question}\n",
    "    ],\n",
    "    functions=myfunctions,\n",
    ")\n",
    "\n",
    "# response ëŠ” ChatCompletion íƒ€ì… ê°ì²´. ê·¸ì•ˆì— ì†ì„±ì€ ê°ì²´ íƒ€ì… or ë¬¸ìì—´\n",
    "print(f'log response : {response.model_dump_json(indent=2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ff4479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„log fn_name: get_current_time\n",
      "log : 12:09:54\n",
      "{\n",
      "  \"id\": \"chatcmpl-CYkfhm8nopWhcVtuMmcjNDUKvL0no\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"í˜„ì¬ ì‹œê°„ì€ 12ì‹œ 09ë¶„ 54ì´ˆì…ë‹ˆë‹¤.\",\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"annotations\": [],\n",
      "        \"audio\": null,\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1762398593,\n",
      "  \"model\": \"gpt-4.1-mini-2025-04-14\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": \"default\",\n",
      "  \"system_fingerprint\": \"fp_4c2851f862\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 15,\n",
      "    \"prompt_tokens\": 100,\n",
      "    \"total_tokens\": 115,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"accepted_prediction_tokens\": 0,\n",
      "      \"audio_tokens\": 0,\n",
      "      \"reasoning_tokens\": 0,\n",
      "      \"rejected_prediction_tokens\": 0\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"audio_tokens\": 0,\n",
      "      \"cached_tokens\": 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "ğŸ’¬AI : í˜„ì¬ ì‹œê°„ì€ 12ì‹œ 09ë¶„ 54ì´ˆì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# í•¨ìˆ˜ í˜¸ì¶œì„ í•˜ê³  ë‹µë³€ì„ ë§Œë“œëŠ” ì¶”ê°€ì ì¸ ìš”ì²­ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "# í•¨ìˆ˜ëŠ” 1ê°œë§Œ í˜¸ì¶œ ê°€ëŠ¥í•¨\n",
    "import json\n",
    "# fn_name = response.choices[0].message.function_call.name\n",
    "fn_name = getattr(response.choices[0].message.function_call,'name',None)\n",
    "print(f'ğŸ”„log fn_name: {fn_name}')\n",
    "if fn_name:\n",
    "    func_response = globals()[fn_name]() # ë¬¸ìì—´ë¡œ ëœ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ëŠ” ë°©ë²•\n",
    "    followup_response = client.chat.completions.create(\n",
    "        model='gpt-4.1-mini',\n",
    "        messages=[\n",
    "            {\"role\":\"system\",\"content\":\"You are a helpful assistant.using locale language.\"},\n",
    "            {\"role\":\"user\",\"content\":f'{fn_name} í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•œ ê²°ê³¼ {func_response} ì´ìš©í•˜ì—¬ ìµœì¢… ì‘ë‹µ ë§Œë“¤ì–´ì¤˜.'}\n",
    "        ],\n",
    "        functions=myfunctions\n",
    "    )\n",
    "    print(followup_response.model_dump_json(indent=2))\n",
    "    \n",
    "    # í•¨ìˆ˜ ì‹¤í–‰í•œ ë‘ë²ˆì§¸ ìš”ì²­ ì‘ë‹µ\n",
    "    result = followup_response.choices[0].message.content\n",
    "else:\n",
    "    # ì²«ë²ˆì§¸ ìš”ì²­ ì‘ë‹µ\n",
    "    result = response.choices[0].message.content    \n",
    "\n",
    "print(f'ğŸ’¬AI : {result}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
