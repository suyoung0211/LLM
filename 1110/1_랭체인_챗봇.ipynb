{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ebb55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e107de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랭체인으로 모델 객체 생성\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4.1-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cbe1194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕 김땡땡! 반가워요. 어떻게 도와줄까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 24, 'total_tokens': 45, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-CaB30NMsztbw1b7CSrfOu1qps8pOV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--05ba7bd5-4e63-4b86-9b13-24284dc4d58a-0', usage_metadata={'input_tokens': 24, 'output_tokens': 21, 'total_tokens': 45, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프롬프트 role : HumanMessage, SystemMessage, AIMessage 객체로 저장할 수 있음\n",
    "# 요청 보내는 메소드 : invoke()\n",
    "from langchain_core.messages import HumanMessage\n",
    "ai_message = llm.invoke([HumanMessage(content='안녕? 나는 김땡땡이야. 반가워')])\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c49f8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='미안하지만, 이전에 가르쳐준 이름은 기억하지 못해요. 다시 알려주시면 기억하는 데 도움이 될 수 있어요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 19, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-CaB31mje12f4xPbug9oeGa2IBusce', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8ec0cd19-4ceb-4e80-9eba-6f4daeb6ec62-0', usage_metadata={'input_tokens': 19, 'output_tokens': 31, 'total_tokens': 50, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke([HumanMessage(content='내가 전에 가르쳐준 이름 기억하니?')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f483f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6889843",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"너는 사용자를 도와주는 상담사야.\"),  # 초기 시스템 메시지\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b28c076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log ai_response ➡ {\n",
      "  \"content\": \"안녕하세요, 김땡땡님! 만나서 반갑습니다. 오늘 어떻게 도와드릴까요?\",\n",
      "  \"additional_kwargs\": {\n",
      "    \"refusal\": null\n",
      "  },\n",
      "  \"response_metadata\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 26,\n",
      "      \"prompt_tokens\": 36,\n",
      "      \"total_tokens\": 62,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_provider\": \"openai\",\n",
      "    \"model_name\": \"gpt-4.1-mini-2025-04-14\",\n",
      "    \"system_fingerprint\": \"fp_4c2851f862\",\n",
      "    \"id\": \"chatcmpl-CaB97Zh3yoqT80WfPKhJpNB9cXs5H\",\n",
      "    \"service_tier\": \"default\",\n",
      "    \"finish_reason\": \"stop\",\n",
      "    \"logprobs\": null\n",
      "  },\n",
      "  \"type\": \"ai\",\n",
      "  \"name\": null,\n",
      "  \"id\": \"lc_run--dba211f2-cbfd-4e8b-9e8a-c8e61b421445-0\",\n",
      "  \"tool_calls\": [],\n",
      "  \"invalid_tool_calls\": [],\n",
      "  \"usage_metadata\": {\n",
      "    \"input_tokens\": 36,\n",
      "    \"output_tokens\": 26,\n",
      "    \"total_tokens\": 62,\n",
      "    \"input_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"cache_read\": 0\n",
      "    },\n",
      "    \"output_token_details\": {\n",
      "      \"audio\": 0,\n",
      "      \"reasoning\": 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "AI: 안녕하세요, 김땡땡님! 만나서 반갑습니다. 오늘 어떻게 도와드릴까요?\n",
      "AI: 김땡땡님, 당신의 이름은 김땡땡이고 나이는 30살입니다. 다른 궁금한 점이나 도움이 필요하신 게 있으면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "isPrint=True\n",
    "while True:\n",
    "    user_input = input(\"사용자: \")  # 1. 사용자 입력 받기\n",
    "\n",
    "    if user_input == \"exit\":  #2.사용자가 대화를 종료하려는지 확인인\n",
    "        break\n",
    "    # 랭체인의 메시지 기록(히스토리) 기능\n",
    "    messages.append(\n",
    "        HumanMessage(user_input)\n",
    "    )  # 사용자 메시지를 대화 기록에 추가 \n",
    "    \n",
    "    ai_response = llm.invoke(messages)  # 대화 기록을 기반으로 AI 응답 가져오기\n",
    "    if isPrint:\n",
    "      print(f\"log ai_response ➡ {ai_response.model_dump_json(indent=2)}\")\n",
    "      isPrint=False\n",
    "    messages.append(\n",
    "        ai_response\n",
    "    )  # AI 응답 대화 기록에 추가하기\n",
    "\n",
    "    print(\"AI: \" + ai_response.content)  # AI 응답 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "446ca16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='너는 사용자를 도와주는 상담사야.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='나는 김땡땡이고 30살이야', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='안녕하세요, 김땡땡님! 만나서 반갑습니다. 오늘 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 36, 'total_tokens': 62, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-CaB97Zh3yoqT80WfPKhJpNB9cXs5H', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--dba211f2-cbfd-4e8b-9e8a-c8e61b421445-0', usage_metadata={'input_tokens': 36, 'output_tokens': 26, 'total_tokens': 62, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='내 이름이랑 나이 뭐야', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='김땡땡님, 당신의 이름은 김땡땡이고 나이는 30살입니다. 다른 궁금한 점이나 도움이 필요하신 게 있으면 말씀해 주세요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 78, 'total_tokens': 123, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-CaB9FE9VuuspqaxiDUvAWm2JXh3ht', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--a5b9e963-c4d7-41e6-a9ba-0b4ae4038d36-0', usage_metadata={'input_tokens': 78, 'output_tokens': 45, 'total_tokens': 123, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4f4fa1",
   "metadata": {},
   "source": [
    "### 참고\n",
    "| 모델 제공자         | LangChain 클래스 객체 이름     | import 경로                          | 설명 |\n",
    "|------------------|------------------------------|-------------------------------------|------|\n",
    "| OpenAI           | `ChatOpenAI`                 | `from langchain_openai import ChatOpenAI` | GPT-3.5, GPT-4 등 OpenAI 모델용 |\n",
    "| Azure OpenAI     | `AzureChatOpenAI`            | `from langchain_openai import AzureChatOpenAI` | Azure에서 제공하는 OpenAI 모델 |\n",
    "| Anthropic        | `ChatAnthropic`              | `from langchain_anthropic import ChatAnthropic` | Claude 모델용 |\n",
    "| Cohere           | `ChatCohere`                 | `from langchain_cohere import ChatCohere` | Command R 등 Cohere 모델용 |\n",
    "| Google Vertex AI | `ChatGoogleVertexAI`         | `from langchain_google_vertexai import ChatGoogleVertexAI` | Gemini, PaLM 모델용 |\n",
    "| Hugging Face     | `ChatHuggingFace`            | `from langchain_huggingface import ChatHuggingFace` | Transformers 기반 모델용 |\n",
    "| Ollama           | `ChatOllama`                 | `from langchain_community.chat_models import ChatOllama` | 로컬 LLM 실행용 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
